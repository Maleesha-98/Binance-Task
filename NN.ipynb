{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce42ca30-5abc-40fd-bf6b-b4e977e19243",
   "metadata": {},
   "source": [
    "# Library Tools and Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce0f6f6-cdfb-4cc0-842d-86b9b55acfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e873f-f376-4d9c-9ac8-2e83470b4a4e",
   "metadata": {},
   "source": [
    "# General Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ce2f8d-cb7f-4639-9524-a7b3087a0968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97930.13</td>\n",
       "      <td>97982.54</td>\n",
       "      <td>97928.20</td>\n",
       "      <td>97982.53</td>\n",
       "      <td>18.27246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97982.54</td>\n",
       "      <td>97999.98</td>\n",
       "      <td>97944.00</td>\n",
       "      <td>97949.99</td>\n",
       "      <td>9.10211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97949.99</td>\n",
       "      <td>97984.25</td>\n",
       "      <td>97949.99</td>\n",
       "      <td>97984.24</td>\n",
       "      <td>10.24976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97984.24</td>\n",
       "      <td>97984.25</td>\n",
       "      <td>97942.00</td>\n",
       "      <td>97942.00</td>\n",
       "      <td>9.39547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97942.01</td>\n",
       "      <td>97967.99</td>\n",
       "      <td>97892.06</td>\n",
       "      <td>97892.06</td>\n",
       "      <td>21.62757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>94800.00</td>\n",
       "      <td>94872.02</td>\n",
       "      <td>94768.00</td>\n",
       "      <td>94808.02</td>\n",
       "      <td>36.25977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>94808.02</td>\n",
       "      <td>94866.89</td>\n",
       "      <td>94736.00</td>\n",
       "      <td>94816.98</td>\n",
       "      <td>56.18272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>94816.98</td>\n",
       "      <td>94914.61</td>\n",
       "      <td>94800.00</td>\n",
       "      <td>94914.61</td>\n",
       "      <td>50.36162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>94914.61</td>\n",
       "      <td>94971.83</td>\n",
       "      <td>94824.00</td>\n",
       "      <td>94863.49</td>\n",
       "      <td>42.76734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>94863.49</td>\n",
       "      <td>94888.01</td>\n",
       "      <td>94800.00</td>\n",
       "      <td>94800.00</td>\n",
       "      <td>23.12419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         open      high       low     close    volume\n",
       "0    97930.13  97982.54  97928.20  97982.53  18.27246\n",
       "1    97982.54  97999.98  97944.00  97949.99   9.10211\n",
       "2    97949.99  97984.25  97949.99  97984.24  10.24976\n",
       "3    97984.24  97984.25  97942.00  97942.00   9.39547\n",
       "4    97942.01  97967.99  97892.06  97892.06  21.62757\n",
       "..        ...       ...       ...       ...       ...\n",
       "414  94800.00  94872.02  94768.00  94808.02  36.25977\n",
       "415  94808.02  94866.89  94736.00  94816.98  56.18272\n",
       "416  94816.98  94914.61  94800.00  94914.61  50.36162\n",
       "417  94914.61  94971.83  94824.00  94863.49  42.76734\n",
       "418  94863.49  94888.01  94800.00  94800.00  23.12419\n",
       "\n",
       "[419 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('binance_data.csv',header=None)\n",
    "columns = ['timestamp','open','high','low','close','volume']\n",
    "data.columns = columns\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "data=data.drop(['timestamp'],axis = 1 )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1526f8-b3ff-4110-b717-e7d538e8195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open      0\n",
       "high      0\n",
       "low       0\n",
       "close     0\n",
       "volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff455da-a74f-4541-9c73-6c3c088ab1ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2ff07-0099-4d41-b4d0-001a8b9f12c6",
   "metadata": {},
   "source": [
    "# Data scaling & Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7cf1825-f739-439e-8c85-cddfa6a31dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data[['open', 'high', 'low', 'volume']].values\n",
    "y_raw = data[['close']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c95fdf-71c0-4ffe-a808-5e3ef5df0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler() \n",
    "\n",
    "X = scaler_X.fit_transform(X_raw)\n",
    "y = scaler_y.fit_transform(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f22962-f825-4b42-b44e-8513551929d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8dd92b-5f82-4cb6-ac74-fa77b80b8107",
   "metadata": {},
   "source": [
    "# Neural Network - ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157644fb-6910-4a5e-b77f-81dc576cef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons = X_train.shape[1]  # Number of predictors which is 4 because I got 4 predictors in the data set \n",
    "hidden_neurons = 7  # Neurons in the hidden layer -> Randomly select 7; we can change it.\n",
    "output_neurons = 1  # Single output (price) -> As the output, we need the closing prices in unsee time units, which implies one node is enough. \n",
    "learning_rate = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d4e356b-1e37-4e25-83ad-889fada3bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "W1 = np.random.randn(input_neurons, hidden_neurons) * 0.01\n",
    "b1 = np.zeros((1, hidden_neurons))\n",
    "W2 = np.random.randn(hidden_neurons, output_neurons) * 0.01\n",
    "b2 = np.zeros((1, output_neurons))\n",
    "\n",
    "# Since the goal is to begin the neural network in a neutral state, no numerical values for bias were used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac64fb95-3104-4aa6-991b-7e53db9b2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "def relu_derivative(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "#  1) Use relu activation for the hidden layer and just linear activation for the output layer since the desired output is price, \n",
    "# which is a numerical value; if sigmoid was used, it would yield a probability value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c489bc-1aa4-4d0d-bc7e-dd87e5a2af59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2681\n",
      "Epoch 100, Loss: 0.0801\n",
      "Epoch 200, Loss: 0.0767\n",
      "Epoch 300, Loss: 0.0765\n",
      "Epoch 400, Loss: 0.0762\n",
      "Epoch 500, Loss: 0.0757\n",
      "Epoch 600, Loss: 0.0749\n",
      "Epoch 700, Loss: 0.0735\n",
      "Epoch 800, Loss: 0.0713\n",
      "Epoch 900, Loss: 0.0678\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Detailed in a separate PDF \n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation \n",
    "    Z1 = np.dot(X_train, W1) + b1 \n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2  # Linear activation for regression\n",
    "    A2 = Z2\n",
    "\n",
    "    # Compute loss (Mean Squared Error)\n",
    "    loss = np.mean((A2 - y_train) ** 2)\n",
    "\n",
    "    # Backward propagation \n",
    "    dA2 = 2 * (A2 - y_train) / y_train.shape[0]  # Derivative of MSE w.r.t A2\n",
    "    dZ2 = dA2  # Linear activation derivative\n",
    "    dW2 = np.dot(A1.T, dZ2)\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = np.dot(X_train.T, dZ1)\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e796b-c9dc-4d37-b2b2-87c2c0cbac8c",
   "metadata": {},
   "source": [
    "# Prediction Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbc4fdc1-4a6f-4895-8c08-acc6dc6c212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_new):\n",
    "    Z1 = np.dot(X_new, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    return Z2  # Linear activation gives raw predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b085683-0910-44e9-8384-2797627687a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_predictions = predict(X_test)\n",
    "predictions = scaler_y.inverse_transform(scaled_predictions)  # Inverse transform to get original prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f41031af-9fe0-4542-8e40-1fee670f89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_original = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d77efd-9f92-4a6e-92ce-8c319218fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 719858.3745\n"
     ]
    }
   ],
   "source": [
    "test_loss = np.mean((predictions - y_test_original) ** 2)\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff57addf-1d84-4c11-8795-e6041cebdbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 94987.99, Predicted: 95941.03\n",
      "Actual: 95887.99, Predicted: 96024.88\n",
      "Actual: 97687.98, Predicted: 96206.27\n",
      "Actual: 97023.51, Predicted: 96146.15\n",
      "Actual: 96139.99, Predicted: 96044.45\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):  # Display 5 predictions\n",
    "    print(f\"Actual: {y_test_original[i][0]:.2f}, Predicted: {predictions[i][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a6c18-b10a-43f6-9026-b98c9ce288e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ddb1b-71fa-4546-92c3-c1cd6a26738e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
